{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b5cf904",
   "metadata": {},
   "source": [
    "setup.\n",
    "get our features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2840b0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team_a_home</th>\n",
       "      <th>series_game_number</th>\n",
       "      <th>team_a_series_wins</th>\n",
       "      <th>team_b_series_wins</th>\n",
       "      <th>series_diff</th>\n",
       "      <th>season_start_year</th>\n",
       "      <th>team_a_win</th>\n",
       "      <th>team_a_po_rating</th>\n",
       "      <th>team_a_po_rating_var</th>\n",
       "      <th>team_b_po_rating</th>\n",
       "      <th>team_b_po_rating_var</th>\n",
       "      <th>team_a_rs_rating</th>\n",
       "      <th>team_a_rs_rating_var</th>\n",
       "      <th>team_b_rs_rating</th>\n",
       "      <th>team_b_rs_rating_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>30.566319</td>\n",
       "      <td>9.632559</td>\n",
       "      <td>24.958216</td>\n",
       "      <td>8.521260</td>\n",
       "      <td>39.456857</td>\n",
       "      <td>6.396895</td>\n",
       "      <td>31.614513</td>\n",
       "      <td>5.668099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>30.403871</td>\n",
       "      <td>9.433143</td>\n",
       "      <td>24.817969</td>\n",
       "      <td>9.065302</td>\n",
       "      <td>39.456857</td>\n",
       "      <td>6.396895</td>\n",
       "      <td>31.614513</td>\n",
       "      <td>5.668099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>30.330679</td>\n",
       "      <td>9.263566</td>\n",
       "      <td>24.686693</td>\n",
       "      <td>8.728343</td>\n",
       "      <td>39.456857</td>\n",
       "      <td>6.396895</td>\n",
       "      <td>31.614513</td>\n",
       "      <td>5.668099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>32.113724</td>\n",
       "      <td>9.537321</td>\n",
       "      <td>28.347514</td>\n",
       "      <td>9.273886</td>\n",
       "      <td>39.456857</td>\n",
       "      <td>6.396895</td>\n",
       "      <td>31.614513</td>\n",
       "      <td>5.668099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>28.617827</td>\n",
       "      <td>8.617034</td>\n",
       "      <td>24.799651</td>\n",
       "      <td>8.607696</td>\n",
       "      <td>39.456857</td>\n",
       "      <td>6.396895</td>\n",
       "      <td>31.614513</td>\n",
       "      <td>5.668099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   team_a_home  series_game_number  team_a_series_wins  team_b_series_wins  \\\n",
       "0            1                 1.0                   0                   0   \n",
       "1            1                 2.0                   1                   0   \n",
       "2            0                 3.0                   2                   0   \n",
       "3            0                 4.0                   2                   1   \n",
       "4            1                 5.0                   3                   1   \n",
       "\n",
       "   series_diff  season_start_year  team_a_win  team_a_po_rating  \\\n",
       "0            0               2009           1         30.566319   \n",
       "1            1               2009           1         30.403871   \n",
       "2            2               2009           0         30.330679   \n",
       "3            1               2009           1         32.113724   \n",
       "4            2               2009           1         28.617827   \n",
       "\n",
       "   team_a_po_rating_var  team_b_po_rating  team_b_po_rating_var  \\\n",
       "0              9.632559         24.958216              8.521260   \n",
       "1              9.433143         24.817969              9.065302   \n",
       "2              9.263566         24.686693              8.728343   \n",
       "3              9.537321         28.347514              9.273886   \n",
       "4              8.617034         24.799651              8.607696   \n",
       "\n",
       "   team_a_rs_rating  team_a_rs_rating_var  team_b_rs_rating  \\\n",
       "0         39.456857              6.396895         31.614513   \n",
       "1         39.456857              6.396895         31.614513   \n",
       "2         39.456857              6.396895         31.614513   \n",
       "3         39.456857              6.396895         31.614513   \n",
       "4         39.456857              6.396895         31.614513   \n",
       "\n",
       "   team_b_rs_rating_var  \n",
       "0              5.668099  \n",
       "1              5.668099  \n",
       "2              5.668099  \n",
       "3              5.668099  \n",
       "4              5.668099  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# features we're working with below\n",
    "numerical_features = ['rs_rating_diff', 'po_rating_diff', 'series_diff', 'series_game_number']\n",
    "categorical_features = ['team_a_home'] # not including season_start_year- pipeline will run after splitting, we want to drop it. target already dropped\n",
    "\n",
    "# load, drop columns. will drop season start year later- need it for the seasonal CV/test splitting\n",
    "games_df = pd.read_csv(\"output/playoff_features.csv\")\n",
    "games_df = games_df.dropna()\n",
    "\n",
    "games_df = games_df.drop(columns=['game_id', 'game_date', 'team_a_name', 'team_b_name'])\n",
    "games_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9985e028",
   "metadata": {},
   "source": [
    "pipeline? don't need it lol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "890f05ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    min_child_weight=1,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=1,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8888540d",
   "metadata": {},
   "source": [
    "set up train/test split, set up rolling window cross validation splits, apply normalization pipeline + fit model\n",
    "seeing the first basic result here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8d4b8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55421687 0.49411765 0.55172414 0.45238095 0.5       ]\n",
      "Mean CV score: 0.510 +/- 0.038\n"
     ]
    }
   ],
   "source": [
    "# split off the test set\n",
    "seasons = sorted(games_df['season_start_year'].unique())\n",
    "train_seasons = seasons[:-1] # all but the last season\n",
    "test_season = seasons[-1] # last season\n",
    "train_df, test_df = games_df[games_df['season_start_year'].isin(train_seasons)], games_df[games_df['season_start_year'] == test_season]\n",
    "X_test, y_test = test_df.drop(\"team_a_win\", axis=1), test_df[\"team_a_win\"]\n",
    "\n",
    "\n",
    "# split into train and test sets\n",
    "def rolling_window_splits(df : pd.DataFrame, season_col=\"season_start_year\", train_size=10, n_splits=5):\n",
    "    \n",
    "    # sorted list of unique seasons\n",
    "    seasons = sorted(df[season_col].unique())\n",
    "    \n",
    "    # for each CV split... \n",
    "    for i in range(n_splits):\n",
    "        train_seasons = seasons[i : i + train_size]\n",
    "        val_season = seasons[i + train_size]\n",
    "        \n",
    "        train_idx = df[df[season_col].isin(train_seasons)].index\n",
    "        val_idx = df[df[season_col] == val_season].index\n",
    "        yield train_idx, val_idx\n",
    "\n",
    "X_train, y_train = train_df.drop(\"team_a_win\", axis=1), train_df[\"team_a_win\"]\n",
    "scores = cross_val_score(model, X_train, y_train, cv=rolling_window_splits(train_df, train_size=10, n_splits=5), n_jobs=-1)\n",
    "print(scores)\n",
    "print(f\"Mean CV score: {scores.mean():.3f} +/- {scores.std():.3f}\")\n",
    "\n",
    "# loop of CV splits\n",
    "# for train_idx, val_idx in rolling_window_splits(games_df, train_size=10, n_splits=5):\n",
    "#     train_df = games_df.loc[train_idx].drop(columns=[\"season_start_year\"])\n",
    "#     val_df = games_df.loc[val_idx].drop(columns=[\"season_start_year\"])\n",
    "    \n",
    "#     X_train, y_train = train_df.drop(\"team_a_win\", axis=1), train_df[\"team_a_win\"]\n",
    "#     X_val, y_val = val_df.drop(\"team_a_win\", axis=1), val_df[\"team_a_win\"]\n",
    "    \n",
    "#     pipeline.fit(X_train, y_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8371a59",
   "metadata": {},
   "source": [
    "hyperparameter tuning now- start with random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6af59525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "{'colsample_bytree': np.float64(0.9497270419417668), 'gamma': np.float64(0.25761802743210543), 'learning_rate': np.float64(0.3019331047810313), 'max_depth': 7, 'min_child_weight': 3, 'n_estimators': 502, 'reg_alpha': np.float64(0.8217906368444492), 'reg_lambda': np.float64(0.8450826278223867), 'subsample': np.float64(0.7390476857930735)}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the parameter distributions\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 800),\n",
    "    'max_depth': randint(3, 10),\n",
    "    'learning_rate': uniform(0.01, 0.3),         # 0.01 to 0.31\n",
    "    'subsample': uniform(0.6, 0.4),              # 0.6 to 1.0\n",
    "    'colsample_bytree': uniform(0.6, 0.4),       # 0.6 to 1.0\n",
    "    'min_child_weight': randint(1, 10),\n",
    "    'gamma': uniform(0, 0.5),\n",
    "    'reg_alpha': uniform(0, 1),                  # L1 regularization\n",
    "    'reg_lambda': uniform(0.5, 1.0)              # L2 regularization\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier(eval_metric='logloss')\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=100,                  # number of random configs to try\n",
    "    scoring='accuracy',         # or 'neg_log_loss' / 'roc_auc'\n",
    "    cv=rolling_window_splits(train_df, train_size=10, n_splits=5),\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit to your training data\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(search.best_params_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e6959b",
   "metadata": {},
   "source": [
    "grid search based on random search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e08d8395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV score: 0.567\n",
      "Best params: {'colsample_bytree': np.float64(0.9497270419417668), 'gamma': np.float64(0.283379830175316), 'learning_rate': np.float64(0.3019331047810313), 'max_depth': 8, 'min_child_weight': 4, 'n_estimators': 452, 'reg_alpha': np.float64(0.9039697005288941), 'reg_lambda': np.float64(0.8450826278223867), 'subsample': np.float64(0.8129524543723808)}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# random_search_best_params = {'colsample_bytree': np.float64(0.9497270419417668), \n",
    "#                              'gamma': np.float64(0.25761802743210543), \n",
    "#                              'learning_rate': np.float64(0.3019331047810313), \n",
    "#                              'max_depth': 7, \n",
    "#                              'min_child_weight': 3, \n",
    "#                              'n_estimators': 502, \n",
    "#                              'reg_alpha': np.float64(0.8217906368444492), \n",
    "#                              'reg_lambda': np.float64(0.8450826278223867), \n",
    "#                              'subsample': np.float64(0.7390476857930735)}\n",
    "\n",
    "\n",
    "def generate_search_grid(params):\n",
    "    grid = {}\n",
    "    for key, value in params.items():\n",
    "        if isinstance(value, np.float64):\n",
    "            grid[key] = [max(.001, value - 0.1*value), value, min(1, value + 0.1*value)]\n",
    "        elif isinstance(value, int):\n",
    "            grid[key] = [min(value - 1, value - value//10), value, max(value + 1, value + value//10)]\n",
    "    return grid\n",
    "\n",
    "param_grid = generate_search_grid(search.best_params_)\n",
    "# print(param_grid)\n",
    "    \n",
    "grid = GridSearchCV(xgb, param_grid, cv=rolling_window_splits(train_df, train_size=10, n_splits=5), n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "print(f\"Best CV score: {grid.best_score_:.3f}\")\n",
    "print(f\"Best params: {grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e23077",
   "metadata": {},
   "source": [
    "train the final model with the full training set + the results from grid searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432a2de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['output/logistig_reg_model.pkl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_cv_best_model = grid.best_estimator_\n",
    "post_cv_best_model.fit(X_train, y_train)\n",
    "\n",
    "# evaluate on the test set\n",
    "test_score = post_cv_best_model.score(X_test, y_test)\n",
    "print(f\"Test score: {test_score:.3f}\")\n",
    "\n",
    "# save the model\n",
    "import joblib\n",
    "joblib.dump(post_cv_best_model, \"output/boosted_tree.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
