{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b5cf904",
   "metadata": {},
   "source": [
    "setup.\n",
    "get our features, create normalization/regularization pipeline, define our model + loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2840b0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from merge_features import load_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# pipeline - TODO\n",
    "\n",
    "# loss function - TODO\n",
    "\n",
    "# model TODO\n",
    "\n",
    "# load, drop columns\n",
    "games_df = load_data()\n",
    "games_df = games_df.drop(columns=['game_id', 'game_date', 'home_team', 'away_team'])\n",
    "games_df = games_df.dropna()\n",
    "games_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8888540d",
   "metadata": {},
   "source": [
    "set up train/test split, set up rolling window cross validation splits, apply normalization/regularization pipeline + fit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d4b8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "def rolling_window_splits(df : pd.DataFrame, season_col=\"season_start_year\", train_size=10, n_splits=5):\n",
    "    \n",
    "    # sorted list of unique seasons\n",
    "    seasons = sorted(df[season_col].unique())\n",
    "    \n",
    "    # for each CV split... \n",
    "    for i in range(n_splits):\n",
    "        train_seasons = seasons[i : i + train_size]\n",
    "        val_season = seasons[i + train_size]\n",
    "        \n",
    "        train_idx = df[df[season_col].isin(train_seasons)].index\n",
    "        val_idx = df[df[season_col] == val_season].index\n",
    "        yield train_idx, val_idx\n",
    "\n",
    "# loop of CV splits\n",
    "for train_idx, val_idx in rolling_window_splits(games_df, train_size=10, n_splits=5):\n",
    "    train_df = games_df.loc[train_idx].drop(columns=[\"season_start_year\"])\n",
    "    val_df = games_df.loc[val_idx].drop(columns=[\"season_start_year\"])\n",
    "    \n",
    "    X_train, y_train = train_df.drop(\"team_a_win\", axis=1), train_df[\"team_a_win\"]\n",
    "    X_val, y_val = val_df.drop(\"team_a_win\", axis=1), val_df[\"team_a_win\"]\n",
    "    \n",
    "    # here is where you would apply the pipeline, then fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8371a59",
   "metadata": {},
   "source": [
    "after X-validation we're selecting our hyperparameters, training on the full non-test set, and getting our final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af59525",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
